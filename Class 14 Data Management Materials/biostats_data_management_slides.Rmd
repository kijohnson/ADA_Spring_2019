---
title: 'Data Management'
author: "Joseph Anthony, Laura Gardner, Kyle Pitzer"
output:
  slidy_presentation:
    highlight: haddock
  beamer_presentation:
    highlight: haddock
  ioslides_presentation:
    highlight: haddock
---

```{r setup, include=FALSE}
# To change this to a packet for printing instead of slides
# delete the line in the heading at the top that says "output:" and all the lines after it 
# up to the --- (leave the --- there)
# replace with one line that says "output: html_document" in the output field
# to any of the code chunks you want to see in the packet, add echo = TRUE 
# inside the curly brackets around the {r} at the top of the chunk like this
# {r echo=TRUE} and knit to make a packet
knitr::opts_chunk$set(message = FALSE, warning = FALSE, echo=FALSE)
```

# Outline: Messy and missing data

These slides dip a toe in the water of the vast ocean called _data management_:

1. Coding missing values
2. Understanding missing value patterns
3. Recoding continuous variables to categorical
4. Collapsing categorical variables into fewer categories
5. Identifying and correcting out-of-range values
6. Loading data from different software packages

For this workshop you will need the following packages: descr, car, tidyverse, VIM, assertr, foreign, sas7bdat 

# A quick review

1)  Datasets 
* A collection of data
* data are measurable points of information 

2)  Variables
* a quantity, quality, or property that can be measured 
* A data set is comprised of variables 

3)  Observations 
* A set of measurements of which a variable is comprised 
* Base unit of measurement 
* A data set is also comprised of observations 

# Messy and missing data

Definitions:

Tony Fischetti: "Messy" data = 

* Many missing values 
* Misspelling of variables 
* Inconsistent coding 
* Different unit values for the same variable 
* Data entry mistakes 
* Extreme outliers

# Types of missing data 

* Missing data can be random or systematic

* Missing completely at random: (MCAR)
    + Reasons for missing values are not related to observed variables or other measureable characteristics
    + Occur entirely at random 
    + Analysis performed on the data is unbiased  
    + Usually an unrealistically strong assumption in practice 

* Missing at random: (MAR) 
    + Missingness is not COMPLETELY at random, but can be accounted for by observed variables 
        + For example, perhaps males were less likely to answer questions about depression on a survey 
        + However, the reason males skipped the depression question had nothing to do with their level of depression 
    + MAR is impossible to verify statistically, we must rely on its reasonableness 
    + Data with values that are MAR can be biased 
    + There are methods you will learn in intermediate stats for estimating models that account for MAR data and give unbiased estimates 
    
# Types of missing data (continued)

* Missing not at random: (MNAR)
    + The information that is missing is related to the reason it is missing
    + This would occur if a certain group (e.g., males, older adults) failed to fill in a depression survey because their level of depression (e.g., they had higher depression than other groups)
    + This sort of missing results in the most bias 
    
# Why does missing data happen?

* Intentional Coding: an event did not occur (flight was cancelled, polling place was not open, etc.) 
    + In these cases, we usually don't want to delete or omit the data, just want to code it differently
* Survey non-response 
* Data entry mistakes 

<center>
![](but-why.png)

# Important to understand because...

* Missing values can impact analysis; they can change results so findings from a sample are not providing a true sense of what is going on in the population 

* If the missing values are random, they can be dealt with in analysis and data management 

* If missing values are not random, then larger bias may exist and we likely need to re-collect data or rethink our research design 

* Most missing data are not completely random and possible reasons for non-randomness would be part of writing conclusions (e.g., "more men were missing the depression data, which may have biased results") 

# Deal with it

* How do we identify missing data in datasets?
    + R recognizes "NA" as missing
        + Data where missing is coded as something else should be recoded
    + Often have to look at the data and codebook to understand what "NA" means and how it is used in each dataset 
    + Summarize command in RStudio 

* How do we deal with missing data?
    + Don't have any (LOL): This rarely happens
    + Imputation/Imputed models: Filling in the missing with a value based on other characteristics of the data (controversial)
    + Removal: Dropping observations or parts of observations
    + Recoding: Include missing as a category in the analyses

<center>
![](yoda.png)

# Coding missing values

* R recognizes a data point entered as NA as a missing value 
* This is not the same for all software packages and so some data sets may have missing values as blank cells or coded as "999" or some other value
* The summary function can help determine if missing values are coded as NA or something else  
* For example, check the coding of variables in the smokers data set: 

```{r echo = TRUE}
# import the data and call the data frame smokers
smokers <- read.csv("http://tinyurl.com/z2m3cgq")
```

```{r echo = TRUE, eval = FALSE}
# get a summary of the data
summary(smokers)
```

# Examine a single variable 

Start by looking at the _Income_ variable more closely by just typing the name of the variable or using the freq command. 

```{r echo = TRUE}
# print out the value of the income variable for each person
# in the data 
smokers$Income
```

# The frequency table shows missing data codes

* Notice that there are two codes that represent missing data: "77-Don't Know" and "99-Refused"
* R considers these legitimate categories of this variable since they are not NA and includes them in analyses

```{r echo = TRUE}
# get a table of the values of income
library(descr)
freq(smokers$Income, plot=F)
```

# Example of missing values in analyses  

```{r echo = FALSE, eval = TRUE}
# conduct a chi-squared with income variable
# to see the missing values included 
# that influence the chi-squared results 
CrossTable(smokers$Income, smokers$sex, chisq = TRUE, prop.c=F,
           prop.t=F, prop.chisq=F, sresid=T)
```

# Starting to figure out missing data

* In conducting analyses, we often do not want to include a small number of missing values as an actual category of the data, so recoding these to be considered missing is one possible strategy
* To retain the original coding in case it becomes useful to know the _Refused_ from the _Don't know_ categories, we can create a new variable.
* In previous workshops, we have used the car package's recode command to recode variables. Here, it doesn't quite work due to the use of double and single quotes in the code (i.e. "Don't" in "Don't Know" creates a problem) 
* To use car::recode, you will have to rename that category of the variable
* In tidyverse, which is a collection of commonly used packages in R, there is a package called _dplyr_ 
* Within dplyr, there is a function called fct_recode to accomplish this change so one can continue using car::recode 

# Using fct_recode to recode, then use car

```{r echo = TRUE}
# use the tidyverse fct_recode to get rid of the apostrophe
# fct_recode means factor recode so is useful for categorical variables
library(tidyverse)
smokers$Income.frec <- fct_recode(smokers$Income, 
                                  "77-Dont Know" = "77-Don't Know")
#check with levels()
levels(smokers$Income.frec)

# use the recode command in the car package to recode the updated variable
library(car)
smokers$Income.crec <- car::recode(smokers$Income.frec,
                                  "'77-Dont Know' = NA;
                                  '99-Refused' = NA")
```

# Check the newly recoded variable

```{r echo = TRUE}
# check your work with a frequency table (uses descr package)
freq(smokers$Income.crec, plot=FALSE)
```

# Use dplyr for the whole process instead

* Instead of using two packages, the recode in dplyr is not subject to the apostrophe limitation
* Use dplyr::recode if you have both the car and dplyr packages loaded
* Try recoding to a new variable to preserve the original: 

```{r echo=TRUE}
# recode income to a new variable
smokers$Income.drec <- dplyr::recode(smokers$Income, 
                                   "77-Don't Know" = NA_character_, 
                                   "99-Refused" = NA_character_)
freq(smokers$Income.drec, plot=FALSE)
```

# Examine the chi-squared again to see what changed

```{r}
# chi-squared with newly recoded variable 
CrossTable(smokers$Income.drec, smokers$sex, chisq = TRUE, prop.c=F,
           prop.t=F, prop.chisq=F, sresid=T)
```

# Try it with the VBMI4CAT variable

Examine the BMI variable:

```{r echo = TRUE}
# examine the variable
freq(smokers$VBMI4CAT, plot=F)
```

* There are 4 blank cells that are not being treated as missing
* This time it is not necessary to retain the original variable since we are just replacing blanks with NA values  

# Replacing the blank cells

* For replacing a single value with NA, dplyr has a handy function called na_if, like this:

```{r echo = TRUE}
# replace blank values with NA 
smokers$VBMI4CAT <- na_if(smokers$VBMI4CAT,"") 
# check your work
freq(smokers$VBMI4CAT, plot=F)
```

# Using droplevels to get rid of unused categories

* The droplevels command removes any categories with no observations:

```{r echo = TRUE}
# remove categories with no observations
smokers$VBMI4CAT<-droplevels(smokers$VBMI4CAT)
freq(smokers$VBMI4CAT, plot=F)
```

Perfecto! 

# You try it!

Fill in the blanks to recode the Refused category in marital_status to NA.

```{r echo = TRUE, eval = FALSE}
#fill in the blank to look at frequencies of the variable
_________(smokers$marital_status)
# fill in the blank to add the command to change "9-Refused" to NA
smokers$marital_status <-  _________(smokers$marital_status,"9-Refused")

# fill in the blank to drop the unused categories in marital status
smokers$marital_status<-________________(smokers$marital_status)

# check the work
freq(smokers$marital_status, plot=F)

```

# You try it correct code

```{r echo = TRUE}
#look at the variable
freq(smokers$marital_status, plot=F)
#change "9-Refused" to NA
smokers$marital_status <-  na_if(smokers$marital_status,"9-Refused")
#drop the unused categories in marital status
smokers$marital_status<-droplevels(smokers$marital_status)
#check your work
freq(smokers$marital_status, plot=F)
```

# Understanding missing value patterns

* When building statistical models with methods like linear and logistic regression, sometimes you find that the number of observations your model is based on is far fewer than the number of observations in your data set
* This often means that there is one variable or a couple of variables with a lot of missing data 
* In most analyses, observations with missing data are dropped 
* If you do have one variable in a regression model that is missing a lot of data, it might be useful to drop the variable from the model so that the model is based on more data
* For example, often people do not give income on surveys
* If your income variable were missing 50% of the values, you might use something else in your model like education or insurance status to represent socioeconomic status 
* Missing 10% or more is a good threshold to start paying attention to missing

# Using VIM to figure out which variables are missing data

* To figure out which variables might be problematic, there is a package called VIM
* Open VIM and run the aggr command to check the patterns of missing data in the smokers data set 
* To get the number of missing values for each variable, start by using the plot=FALSE option 

```{r echo = TRUE}
# load VIM and examine the number of missing values
library(VIM)
aggr(smokers, plot=FALSE)
```

# Visualizing the missing data

Use the _combined=TRUE_ option to visualize the missing data.

```{r echo = TRUE}
# use combined = TRUE to get a visual
aggr(smokers, combined=TRUE)
```

# Interpreting the VIM output

* Variables missing the most data are the four variables indicating secondhand smoke exposure in the workplace, car, and public and the support for stronger secondhand smoke policy
* Including any of these variables in a model would result in more than 60 of the 100 observations in the data set to be dropped before the model was estimated
* Other possibly problematic values are numcigs, packyears, and livesmoke. When using these in analyses, nearly one-third of observations would be dropped
* This is important to consider, especially if people missing this information might be somehow different than people with complete data, which can bias results (MNAR = Missing Not At Random)

# Strategy for identifying Missing Not At Random (MNAR)

* One method for figuring out if data has Missing Not At Random (MNAR) is to compare observations with missing values to observations without missing values on characteristics that are important to your research question/analysis 
* For example, in a study to determine differences in heaviness of smoking for males and females, we might want to know if the numcigs and packyears variables are missing significantly more data for males compared to females (or vice-versa) 
* We can test this using this procedure:
    + recode numcigs into a new variable that is 'missing' for missing and 'not missing' for not missing using an if_else function in _dplyr_
    + compare the new variable to the sex variable using chi-squared 

# Example of identifying MNAR

```{r echo = TRUE} 
# recode numcigs to a missingNumcigs variable
smokers$missingNumcigs <- if_else(condition = smokers$numcigs > 0, 
                                  true = "not missing", false = "", 
                                  missing = "missing")
#check the variable
freq(smokers$missingNumcigs, plot=F)
```

# Examine missingness by sex using chi-squared

```{r echo = TRUE}
# examine the relationship of missingNumcigs to
# the sex variable to see if missingNumcigs differs by sex
CrossTable(smokers$sex, smokers$missingNumcigs, chisq=TRUE, prop.c=F, 
           prop.t=F, prop.chisq=F, sresid=T)
```

# Interpreting the MNAR test

* The chi-squared value is not significant, so missing values and sex are not associated 
    + Numcigs data is equally likely to be missing or non-missing for males and females 
* Use a t-test if the predictor of interest is continuous 
* If you do find significant results, this should be noted when you interpret your results as a possible source of bias in the data 
    + Example of noting this: "Missing values were statistically significantly higher on the xxxx variable for males compared to females."

# Other types of missing data (not MNAR)

* There are a number of ways to deal with missing data as long as it is not MNAR. Several are described in the _Fischetti_ text. 
* Nearly all of these methods have major limitations. 
* It is usually best to analyze the complete cases and describe the missingness well so that your reader understands your data. 
* This is the default in most statistical programs, including R.

# You try it!

Fill in the blanks to complete the code for adding a new variable differentiating missing and not missing for packyears and determining if there is a significant association between missing packyears data and sex.

```{r eval = FALSE, echo = TRUE}
# recode packyrs to a missingPackyrs variable
smokers$missingPackyrs <- __________(condition = smokers$packyears > 0, 
                                     ______ = "not missing", false = "",
                                     _________ = "missing")
#check the variable
________(smokers$missingPackyrs, plot=F)

# check the recoding and association with sex
CrossTable(____________, _____________, chisq=TRUE, prop.c=F, 
           prop.t=F, prop.chisq=F, sresid=T)
```

# Correct code for you try it 

```{r echo = TRUE}
# recode packyrs to a missingPackyrs variable
smokers$missingPackyrs <- if_else(condition = smokers$packyears > 0, 
                                  true = "not missing", false = "", 
                                  missing = "missing")
#check the variable
freq(smokers$missingPackyrs, plot=F)

# check the recoding and association with sex
CrossTable(smokers$sex, smokers$missingPackyrs, 
           chisq=TRUE, prop.c=F, 
           prop.t=F, prop.chisq=F, sresid=T)
```

# Recoding continuous variables to categorical

* Research has demonstrated that heavy smokers have different health problems than light or moderate smokers
* Say you were interested in examining the characteristics significantly associated with heavy smoking, where heavy smoking is 1 or more packs of cigarettes per day (20 or more cigarettes)
* We do not have this variable in the smokers data set, but we can create a new variable called _heavy_ from the numcigs variable using the same if_else function

```{r echo=TRUE}
#recode numcigs variable to a heavy smoker variable, yes for a pack or more, no for less
smokers$heavy <- if_else(condition = smokers$numcigs >= 20, 
                         true = "yes", false = "no")

#check your work
freq(smokers$heavy, plot=F)
```

#Checking new variable for correct recode

* When recoding, it is important to check your new variable to make sure it is coded correctly
* The new variable, _heavy_, should have values of _yes_ when numcigs is at least 20 and should have values of _no_ when numcigs is less than 20 
* Check it using the by command with the summary command

```{r echo=TRUE}
#get the summary for numcigs for the two heavy categories
by(smokers$numcigs, smokers$heavy, summary)
```

Looks good!

#Recoding into three categories

* For three categories, you can use multiple ifelse statements with _mutate_ in dplyr.
* The _mutate_ function is used to create new variables in a data set with flexibility in defining the new variable
* This one is slightly different because it uses the base r ifelse function
* Here, we will recode the ageonset variable into three categories: under 18, 18, over 18

```{r echo=TRUE}
#create a new variable called agecat with three categories in the smokers data
smokers <- mutate(smokers, ageOnsetCat = ifelse(ageonset < 18, 
                                                "Under 18",
                ifelse(ageonset == 18, "18",
                ifelse(ageonset > 18, "Over 18", NA))))
#check the variable
freq(smokers$ageOnsetCat, plot = F)
#check your work
by(smokers$ageonset, smokers$ageOnsetCat, summary)
```

# Recoding categorical variables to fewer categories

* Sometimes there are too few people in a category for analysis to be useful
* Basing statistical estimates and results on 1 or 2 people is unreliable at best
* Instead, categories with small numbers of people in them are often combined before analysis
* Examine the employment variable from the smokers data set

```{r echo=FALSE, eval=TRUE}
#get the summary for the employment variable
summary(smokers$employment)
```

#Recoding employment into two categories

* Several of the categories represent people not employed outside the home for various reasons
* While there may be important differences between students, homemakers, retirees, and others, categories with 4 or 5 people in them are not useful for analyses
* Instead, combine those not working for compensation into a single category
* At the same time, combine employed for wages and self-employed into one category

```{r echo=TRUE}
#recode employment into a variable with two categories
smokers$employed <- dplyr::recode(smokers$employment, 
                                  "1-Employed for wages" = "yes",
                                  "2-Self-employed" = "yes",
                                  "3-Out of work for more than 1 year" = "no",
                                  "4-Out of work for less than 1 year" = "no",
                                  "5-A homemaker" = "no",
                                  "6-A student" = "no",
                                  "7-Retired" = "no",
                                  "8-Unable to work" = "no")
#check your work
freq(smokers$employed, plot=F)
```

#Checking the new variable against the old variable

One option to check the recoding when the old and new variables are both categorical is using a table with the old variable and the new variable:

```{r echo=TRUE}
#check the recode against the old variable
table(smokers$employment, smokers$employed)
```

Looks good!

# You try it!

Fill in the blanks to complete the code for recoding the marital status variable into two categories, one for married and one for not married. Check your recoding using the table command. 

```{r}
#get a summary of the marital status variable
freq(smokers$marital_status, plot = FALSE)
```


```{r echo=TRUE, eval=FALSE}
#recode the marital status variable in a variable with two categories
smokers$married <- _____________(smokers$marital_status, 
                                  "__________" = "yes",
                                  "__________" = "no",
                                  "__________" = "no",
                                  "__________" = "no",
                                  "__________" = "no",
                                  "__________" = "no")
#check your work
____________(smokers$married, plot=F)
#check your new variable against the old variable
____________(smokers$marital_status, smokers$married)
```

#Correct code for you try it

```{r echo=TRUE}
#recode the marital status variable in a variable with two categories
smokers$married <- dplyr::recode(smokers$marital_status, 
                                  "1-Married" = "yes",
                                  "2-Divorced" = "no",
                                  "3-Widowed" = "no",
                                  "4-Separated" = "no",
                                  "5-Never married" = "no",
                                  "6-A member of an unmarried couple" = "no")
#check your work
freq(smokers$married, plot=F)
#check your new variable against the old variable
table(smokers$marital_status, smokers$married)
```

# Identifying and correcting out-of-range values and incorrect data types

* Occasionally you will come across a data entry error or miscoded value in your data set
* Sometimes the value can be corrected, and other times the value will have to be replaced with NA
* To find out-of-range values you can use the summary command and review the values for nonsense or, if you suspect an out-of-range value, you can use the assertr package to check
* For example, the age variable in the smokers data should not go below 18 or above 100.
* Check to see if all the age values are in this range


```{r, echo = TRUE, eval=FALSE}
#loading assertr package
library(assertr)
#check to see if any values in age fall outside 18-100
assert(smokers, within_bounds(18,100), age)
```

# Correcting out-of-range values 

* The code above results in an error message:

```{r error=TRUE, warning=TRUE, message=TRUE}
#loading assertr package
library(assertr)
#check to see if any values in age fall outside 18-100
assert(smokers, within_bounds(18,100), age)
``` 

* The error message is actually useful this time, telling us that the variable goes outside that range 2 times and gives us the violations of 199 and 620 
* Once this has an error, we can review the data set to find these out-of-range values for age: 620 and 199 

# Making the corrections

* Correct these values to NA since we don't have the original data set to compare to

```{r echo=TRUE}
#replace 199 with NA
smokers$age <- na_if(smokers$age, 199)
#replace 620 with NA
smokers$age <- na_if(smokers$age, 620)
#check your work
summary(smokers$age)
```

In the past we have used subset and dropped these observations from the data set, which means any statistics we do on the data will not include anything for these two individuals on any variable in the data set. Changing the values to NA allows you to retain more of your data.

# Checking for incorrect categories listed for a factor

* Checking for incorrect categories listed for a factor is also done with the assert command
* For example, the VBMI4CAT variable should have three categories: _Healthy weight_, _Obese_, _Overweight_ 
* Using assert we can see if there are any additional incorrect categories

```{r echo=TRUE, eval=FALSE}
#check to see if there are any unwanted categories in VBMI4CAT
assert(smokers, in_set("Healthy weight","Obese",
                                "Overweight"), VBMI4CAT)
```

# Removing incorrect categories
The incorrect category, _Tall_ can be removed using the same na_if command as above:

```{r echo=TRUE}
#replace Tall with NA
smokers$VBMI4CAT <- na_if(smokers$VBMI4CAT, "Tall")
#check your work
summary(smokers$VBMI4CAT)
```

Whoops, forgot to delete unused categories:
```{r echo=TRUE}
# remove categories with no observations
smokers$VBMI4CAT<-droplevels(smokers$VBMI4CAT)
#check your work
summary(smokers$VBMI4CAT)
```

# Changing data types
* Sometimes data types that should be characters or numeric variables are assigned as factors by R
* Checking a data type uses the _class_ command and changing the data type requires one of several _as_ commands
* For example, numcigs would best be described as integer or numeric
* Use the class command and as commands to check and change data types

```{r echo=TRUE}
#check class of numcigs
class(smokers$numcigs)
#change numcigs to a factor
smokers$numcigs<-as.factor(smokers$numcigs)
#check the change
class(smokers$numcigs)
#change numcigs to a numeric
smokers$numcigs<-as.numeric(smokers$numcigs)
#check the change
class(smokers$numcigs)
```


# Loading data from other software packages

The most common types of data files you will encounter in public health and social work are:

* R data (.Rdata) 
* Excel data (.xls, .xlsx)
* Stata data (.dta)
* SPSS data (.sav)
* SAS data (.sas7bdat)
* Comma separated values (.csv)

Some of these are easy to load, like _Rdata_, which requires just the load command: 

* dataset <- load("nameOfDataSet.Rdata")

Excel files require the _readxl_ package to be installed and opened: 

* library(readxl)

* dataset <- read_xls("nameOfDataSet.xls",header=TRUE)} 

# Loading data from Stata, SPSS, and SAS

* Stata and SPSS data formats require the _foreign_ package
* SAS data format requires the _sas7bdat_ package
* Install them to try loading
* Note: The _haven_ package in tidyverse can also accomplish this goal in a very similar way
* Google "tidyverse haven package" for more information for how this package works

# Stata data
```{r echo = TRUE}
# load foreign package
library(foreign)
# read the Stata data file
schools<-read.dta("https://stats.idre.ucla.edu/stat/stata/examples/ara/anscombe.dta")
# get summary of the data
summary(schools)
```

# SPSS data
```{r echo=TRUE}
# read the SPSS data file
right2work<-read.spss("https://stats.idre.ucla.edu/wp-content/uploads/2016/02/p005.sav", to.data.frame = TRUE)
# get summary of the data
summary(right2work)
```

# SAS data
```{r echo=TRUE}
# load the sas7bdat package
library(sas7bdat)
# read the SAS data file
alcohol<-read.sas7bdat("http://www.principlesofeconometrics.com/sas/alcohol.sas7bdat")
# get summary of the data
summary(alcohol)
```

# Practice activity

There is no challenge for this week, but these skills will come in handy on the final exam and in real life. To practice, read the scenario below and try the tasks below it: 

You are examining health department expenditures predicted by a number of variables included in a small data set. A colleague of yours was working with the data set when her cat walked across the keyboard changing several values and then saving the data set. 

* Use foreign to import the SPSS data set saved at: https://tinyurl.com/y84489qw
* Examine the codebook for the data saved here:  https://drive.google.com/file/d/0B9UP9lGaNL2hYnd4NXlnb09FV0U/view?usp=sharing 
* Conduct the tasks on the next slide  

# Tasks

* Identify and correct any value(s) that appear to be out-of-range or representing a missing value for any of the variables in the data set so that they come up as missing in analyses. Drop levels to clean up any factor variables if needed (Hint: R only recognizes NA as missing). 
* Create a variable that has the value of 1 for missing and 0 for not missing on the revenues variable. Use the appropriate bivariate test to compare mean expenditures for health departments missing and not missing revenues data. Interpret your results including an assessment of whether the revenues variable is MNAR or not.
* HACKER: You are thinking about studying health departments in categories of people served (population variable). Recode population into a categorical variable called servedCat that has 4 levels: <25000; 25000-99999; 100000-499999; 500000+. (hint: look at this slide show on mutate and if_else with ranges:  https://rstudio-pubs-static.s3.amazonaws.com/116317_e6922e81e72e4e3f83995485ce686c14.html#/)
